<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>com.foo</groupId>
    <artifactId>scala-it-docker-poc</artifactId>
    <version>1.0-SNAPSHOT</version>

    <properties>
        <docker.image.tag>cview/spark-test</docker.image.tag>
        <docker.image.version>2.0-SNAPSHOT</docker.image.version>
        <docker.image.alias>spark-test</docker.image.alias>
        <spark.context.port>7077</spark.context.port>

        <scala.version>2.11</scala.version>
        <scalatest.version>2.2.1</scalatest.version>
        <spark.version>1.6.1</spark.version>
        <spark-csv.version>1.5.0</spark-csv.version>
        <scalatest.version>2.2.1</scalatest.version>
        <spark-cassandra-connector.version>1.5.2</spark-cassandra-connector.version>


        <playframework.version>2.3.9</playframework.version>

        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <project.reporting.outputEncoding>${project.build.sourceEncoding}</project.reporting.outputEncoding>
    </properties>

    <build>
        <plugins>
            <plugin>
                <groupId>io.fabric8</groupId>
                <artifactId>docker-maven-plugin</artifactId>
                <version>0.23.0</version>
                <configuration>
                    <startParallel>true</startParallel>
                    <showLogs>true</showLogs>
                    <images>
                        <image>
                            <name>${docker.image.tag}:${docker.image.version}</name>
                            <alias>${docker.image.alias}</alias>
                            <run>
                                <ports>
                                    <port>${spark.context.port}:${spark.context.port}</port>
                                </ports>
                                <cmd>start-master-slave.sh</cmd>
                                <volumes>
                                    <bind>
                                        <volume>
                                            ${project.build.directory}/docker-logs:/usr/lib/spark/logs
                                        </volume>
                                    </bind>
                                </volumes>
                            </run>
                        </image>
                    </images>
                </configuration>
                <executions>
                    <execution>
                        <id>run-container</id>
                        <goals>
                            <goal>start</goal>
                        </goals>
                    </execution>
                    <execution>
                        <id>stop-container</id>
                        <goals>
                            <goal>stop</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>

            <plugin>
                <artifactId>maven-surefire-plugin</artifactId>
                <version>2.20</version>
                <configuration>
                    <excludes>
                        <exclude>**/*IT</exclude>
                    </excludes>
                </configuration>
            </plugin>
            <plugin>
                <artifactId>maven-failsafe-plugin</artifactId>
                <version>2.20</version>
                <configuration>
                    <reuseForks>true</reuseForks>
                    <argLine>-Xmx2048m -XX:MaxPermSize=2048m</argLine>
                    <!-- Un seul fork -->
                    <includes>
                        <include>**/*IT</include>
                    </includes>
                </configuration>
                <executions>
                    <execution>
                        <goals>
                            <goal>integration-test</goal>
                            <goal>verify</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>

            <plugin>
                <groupId>org.scala-tools</groupId>
                <artifactId>maven-scala-plugin</artifactId>
                <version>2.15.2</version>
                <executions>
                    <execution>
                        <goals>
                            <goal>compile</goal>
                            <goal>testCompile</goal>
                        </goals>
                    </execution>
                </executions>
                <configuration>
                    <scalaVersion>${scala.version}</scalaVersion>
                </configuration>
            </plugin>
        </plugins>
    </build>

    <dependencies>
        <dependency>
            <groupId>com.typesafe.netty</groupId>
            <artifactId>netty-http-pipelining</artifactId>
            <version>1.1.4</version>
        </dependency>
        <!--<dependency>-->
        <!--<groupId>org.eclipse.jetty</groupId>-->
        <!--<artifactId>jetty-com.bnpparibas.cev.spark.util</artifactId>-->
        <!--<version>9.3.9.v20160517</version>-->
        <!--</dependency>-->

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_${scala.version}</artifactId>
            <version>${spark.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_${scala.version}</artifactId>
            <version>${spark.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-hive_${scala.version}</artifactId>
            <version>${spark.version}</version>
        </dependency>
        <dependency>
            <groupId>com.datastax.spark</groupId>
            <artifactId>spark-cassandra-connector_${scala.version}</artifactId>
            <version>${spark-cassandra-connector.version}</version>
        </dependency>
        <dependency>
            <groupId>com.databricks</groupId>
            <artifactId>spark-csv_${scala.version}</artifactId>
            <version>${spark-csv.version}</version>
        </dependency>

        <dependency>
            <groupId>org.scalatest</groupId>
            <artifactId>scalatest_${scala.version}</artifactId>
            <version>${scalatest.version}</version>
        </dependency>
        <dependency>
            <groupId>com.holdenkarau</groupId>
            <artifactId>spark-testing-base_${scala.version}</artifactId>
            <version>${spark.version}_0.3.3</version>
        </dependency>
        <dependency>
            <groupId>com.typesafe.play</groupId>
            <artifactId>play-ws_${scala.version}</artifactId>
            <version>${playframework.version}</version>
            <exclusions>
                <exclusion>
                    <groupId>ch.qos.logback</groupId>
                    <artifactId>logback-classic</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>ch.qos.logback</groupId>
                    <artifactId>logback-core</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
    </dependencies>

</project>